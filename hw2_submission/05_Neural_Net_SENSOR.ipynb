{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized optimization\n",
    "\n",
    "Plaigiarism note: I partially took this course in 2020 so some of the analysis and text is repeated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mlrose procedure:\n",
    "\n",
    "1. Define a fitness function\n",
    "- This is the function we want to maximize or minimize, and is used to evaluate the fitness of a state vector.\n",
    "2. Define an optimization problem object\n",
    "3. Select and run a randomized optimization algorithm\n",
    "\n",
    "mlrose fitness functions: https://mlrose.readthedocs.io/en/stable/source/fitness.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "import mlrose\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_hw1 = \"/Users/mikepecorino/Documents/machine_learning/HW1/\"\n",
    "directory_hw2 = \"/Users/mikepecorino/Documents/machine_learning/HW2/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv(directory_hw1 + \"sensor_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define features and response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data_all.columns[data_all.columns.isin([\"subject\", \"activity_raw\", \"activity\", \"tag\", \"fold\", \"response_prop\"]) == False]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_features = data_all[features]\n",
    "train_features = data_all[features][data_all[\"tag\"] == \"train\"]\n",
    "valid_features = data_all[features][data_all[\"tag\"] == \"valid\"]\n",
    "test_features = data_all[features][data_all[\"tag\"] == \"test\"]\n",
    "data_cv_features = data_all[features][data_all[\"tag\"].isin([\"train\", \"valid\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create adjusted response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"activity_sitting\"\n",
    "data_all[response] = np.where(data_all[\"activity\"] == 0, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_response = data_all[response]\n",
    "train_response = data_all[response][data_all[\"tag\"] == \"train\"]\n",
    "valid_response = data_all[response][data_all[\"tag\"] == \"valid\"]\n",
    "test_response = data_all[response][data_all[\"tag\"] == \"test\"]\n",
    "data_cv_response = data_all[response][data_all[\"tag\"].isin([\"train\", \"valid\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cv_features_normalized = normalize(data_cv_features)\n",
    "test_features_normalized = normalize(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on iter: 1 Algorithm: random_hill_climb Random restart: 10 Max attempt: 10 Max iter: 1\n",
      "Done in time: 7.819718837738037 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 2 Algorithm: random_hill_climb Random restart: 10 Max attempt: 10 Max iter: 10\n",
      "Done in time: 42.991997957229614 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 3 Algorithm: random_hill_climb Random restart: 10 Max attempt: 10 Max iter: 20\n",
      "Done in time: 82.41077494621277 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 4 Algorithm: random_hill_climb Random restart: 10 Max attempt: 10 Max iter: 30\n",
      "Done in time: 122.83553218841553 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 5 Algorithm: random_hill_climb Random restart: 10 Max attempt: 10 Max iter: 40\n",
      "Done in time: 161.51280689239502 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 6 Algorithm: random_hill_climb Random restart: 10 Max attempt: 10 Max iter: 50\n",
      "Done in time: 1182.4522652626038 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 7 Algorithm: simulated_annealing Random restart: 10 Max attempt: 10 Max iter: 1\n",
      "Done in time: 0.7886791229248047 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 8 Algorithm: simulated_annealing Random restart: 10 Max attempt: 10 Max iter: 10\n",
      "Done in time: 5.196220874786377 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 9 Algorithm: simulated_annealing Random restart: 10 Max attempt: 10 Max iter: 20\n",
      "Done in time: 10.157680034637451 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 10 Algorithm: simulated_annealing Random restart: 10 Max attempt: 10 Max iter: 30\n",
      "Done in time: 15.072447776794434 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 11 Algorithm: simulated_annealing Random restart: 10 Max attempt: 10 Max iter: 40\n",
      "Done in time: 1364.5635960102081 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 12 Algorithm: simulated_annealing Random restart: 10 Max attempt: 10 Max iter: 50\n",
      "Done in time: 24.892604112625122 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 13 Algorithm: genetic_alg Random restart: 10 Max attempt: 10 Max iter: 1\n",
      "Done in time: 4730.337199211121 with test score: 0.8781812012215813\n",
      "\n",
      "\n",
      "Working on iter: 14 Algorithm: genetic_alg Random restart: 10 Max attempt: 10 Max iter: 10\n",
      "Done in time: 16972.855294942856 with test score: 0.9579233118425518\n",
      "\n",
      "\n",
      "Working on iter: 15 Algorithm: genetic_alg Random restart: 10 Max attempt: 10 Max iter: 20\n",
      "Done in time: 6912.381914138794 with test score: 0.9579233118425518\n",
      "\n",
      "\n",
      "Working on iter: 16 Algorithm: genetic_alg Random restart: 10 Max attempt: 10 Max iter: 30\n",
      "Done in time: 1504.3039610385895 with test score: 0.9579233118425518\n",
      "\n",
      "\n",
      "Working on iter: 17 Algorithm: genetic_alg Random restart: 10 Max attempt: 10 Max iter: 40\n",
      "Done in time: 1513.8940470218658 with test score: 0.9579233118425518\n",
      "\n",
      "\n",
      "Working on iter: 18 Algorithm: genetic_alg Random restart: 10 Max attempt: 10 Max iter: 50\n",
      "Done in time: 2179.8601858615875 with test score: 0.9579233118425518\n",
      "\n",
      "\n",
      "Working on iter: 19 Algorithm: gradient_descent Random restart: 10 Max attempt: 10 Max iter: 1\n",
      "Done in time: 1.2560887336730957 with test score: 0.6596538853070919\n",
      "\n",
      "\n",
      "Working on iter: 20 Algorithm: gradient_descent Random restart: 10 Max attempt: 10 Max iter: 10\n",
      "Done in time: 9.587054014205933 with test score: 0.9175432643366135\n",
      "\n",
      "\n",
      "Working on iter: 21 Algorithm: gradient_descent Random restart: 10 Max attempt: 10 Max iter: 20\n",
      "Done in time: 18.71812081336975 with test score: 0.9823549372242959\n",
      "\n",
      "\n",
      "Working on iter: 22 Algorithm: gradient_descent Random restart: 10 Max attempt: 10 Max iter: 30\n",
      "Done in time: 27.839307069778442 with test score: 0.9847302341364099\n",
      "\n",
      "\n",
      "Working on iter: 23 Algorithm: gradient_descent Random restart: 10 Max attempt: 10 Max iter: 40\n",
      "Done in time: 36.99946117401123 with test score: 0.9850695622667119\n",
      "\n",
      "\n",
      "Working on iter: 24 Algorithm: gradient_descent Random restart: 10 Max attempt: 10 Max iter: 50\n",
      "Done in time: 45.89536714553833 with test score: 0.9864268747879199\n",
      "\n",
      "\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "#Inputs for the Neural Network\n",
    "#- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "algos = [\"random_hill_climb\", \"simulated_annealing\", \"genetic_alg\", \"gradient_descent\"]\n",
    "random_state = 28\n",
    "pop_size = 200\n",
    "mutation_prob = 0.1\n",
    "#Simulated Annealing: decay schedule for temperature\n",
    "schedule = mlrose.ExpDecay(init_temp = 100,\n",
    "                           exp_const = .05,\n",
    "                           min_temp = 1)\n",
    "\n",
    "#Initialize an empty data frame for recording results\n",
    "#- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "mlrose_nn = pd.DataFrame(columns = [\"algorithm\",\n",
    "                                    \"random_restart\",\n",
    "                                    \"max_attempt\",\n",
    "                                    \"max_iter\",\n",
    "                                    \"time\",\n",
    "                                    \"function_evaluations\"\n",
    "                                    \"train_score\",\n",
    "                                    \"test_score\"])\n",
    "\n",
    "#Loop\n",
    "#- - - - - - - - - - - - - - - - - - - - - - - - - - - - - -\n",
    "#Start an iteration counter\n",
    "iter = 1\n",
    "\n",
    "#For each combination of algorithm, max attempt, max iter, and random restarts\n",
    "for algo in algos:\n",
    "    for max_attempt in [10]:\n",
    "        for max_iter in [1, 10, 20, 30, 40, 50]:\n",
    "            for random_restart in [10]:\n",
    "                \n",
    "                #Print message\n",
    "                print(\"Working on iter:\", iter,\n",
    "                      \"Algorithm:\", algo,\n",
    "                      \"Random restart:\", random_restart,\n",
    "                      \"Max attempt:\", max_attempt,\n",
    "                      \"Max iter:\", max_iter)\n",
    "                \n",
    "                #Start the timer\n",
    "                start = time.time()\n",
    "        \n",
    "                #Create the model object\n",
    "                nn_model = mlrose.NeuralNetwork(hidden_nodes = [1500],\n",
    "                                                activation = \"relu\",\n",
    "                                                algorithm = algo,\n",
    "                                                max_iters = max_iter,\n",
    "                                                bias = True,\n",
    "                                                is_classifier = True,\n",
    "                                                learning_rate = 0.0001,\n",
    "                                                early_stopping = True,\n",
    "                                                clip_max = 2,\n",
    "                                                max_attempts = max_attempt,\n",
    "                                                random_state = random_state,\n",
    "                                                pop_size = pop_size,\n",
    "                                                mutation_prob = mutation_prob,\n",
    "                                                schedule = schedule,\n",
    "                                                restarts = random_restart,\n",
    "                                                curve = True)\n",
    "            \n",
    "                \n",
    "                #Fit the model\n",
    "                nn_model.fit(data_cv_features_normalized, data_cv_response)\n",
    "                \n",
    "                #Get the number of function evaluations\n",
    "                function_evaluations = np.argmax(nn_model.fitness_curve) + 1\n",
    "                \n",
    "                #End the timer\n",
    "                end = time.time()\n",
    "                \n",
    "                #Get the total model fitting time\n",
    "                fit_time = end - start\n",
    "                \n",
    "                #Score the model on train and test data\n",
    "                train_pred = nn_model.predict(data_cv_features_normalized)\n",
    "                train_score = accuracy_score(data_cv_response, train_pred)\n",
    "                test_pred = nn_model.predict(test_features_normalized)\n",
    "                test_score = accuracy_score(test_response, test_pred)\n",
    "                \n",
    "                #Add to results list\n",
    "                mlrose_nn = mlrose_nn.append({\"algorithm\": algo,\n",
    "                                              \"random_restart\": random_restart,\n",
    "                                              \"max_attempt\": max_attempt,\n",
    "                                              \"max_iter\": max_iter,\n",
    "                                              \"time\": fit_time,\n",
    "                                              \"function_evaluations\": function_evaluations,\n",
    "                                              \"train_score\": train_score,\n",
    "                                              \"test_score\": test_score},\n",
    "                                             ignore_index = True)\n",
    "                \n",
    "                #Increment the iteration counter\n",
    "                iter = iter + 1\n",
    "                print(\"Done in time:\", fit_time, \"with test score:\", test_score)\n",
    "                print(\"\\n\")\n",
    "\n",
    "#Done\n",
    "print(\"Done\")\n",
    "\n",
    "#Output\n",
    "mlrose_nn.to_csv(directory_hw2 + \"sensor_randomized_opt_neural_net.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
