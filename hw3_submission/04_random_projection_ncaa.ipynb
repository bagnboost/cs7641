{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomized Projection on the NCAA Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scitkit learn random projection: https://scikit-learn.org/stable/modules/random_projection.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from sklearn import random_projection\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory_hw1 = \"/Users/mikepecorino/Documents/machine_learning/HW1/\"\n",
    "directory_hw3 = \"/Users/mikepecorino/Documents/machine_learning/HW3/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = pd.read_csv(directory_hw3 + \"ncaa_all.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data_all[data_all[\"tag\"].isin([\"train\", \"valid\"])]\n",
    "test = data_all[data_all[\"tag\"] == \"test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define features and response variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"game_win_perc_prop\", \n",
    "            \"game_starters_total_minutes_prop\", \"game_starters_prop_minutes_prop\", \"game_player_pts_10plus_prop\",\n",
    "            \"game_player_pts_15plus_prop\", \"game_player_pts_16plus_prop\", \"game_player_pts_17plus_prop\",\n",
    "            \"game_player_pts_18plus_prop\", \"game_player_pts_19plus_prop\", \"game_player_pts_20plus_prop\",\n",
    "            \"game_player_pts_21plus_prop\", \"game_player_pts_22plus_prop\", \"game_player_ast_3plus_prop\",\n",
    "            \"game_player_ast_5plus_prop\", \"game_player_ast_7plus_prop\",\n",
    "            \"game_player_orb_1plus_prop\", \"game_player_orb_2plus_prop\", \"game_player_orb_3plus_prop\",\n",
    "            \"game_player_drb_5plus_prop\", \"game_player_drb_7plus_prop\", \"game_player_drb_10plus_prop\",\n",
    "            \"game_gs_mean_prop\", \"game_gs_max_prop\", \"game_pos_prop\", \"game_pts_prop\", \"game_efficiency_prop\",\n",
    "            \"game_fg_attempted_prop\", \"game_ft_attempted_prop\", \"game_ft_made_prop\", \"game_stl_prop\",\n",
    "            \"game_tov_prop\",\"game_stl_tov_ratio_diff\", \"game_stl_tov_ratio_prop\", \"game_blk_prop\",\n",
    "            \"game_orb_prop\", \"game_drb_prop\", \"game_trb_prop\", \"game_ast_prop\", \"game_pf_diff\", \"game_pf_prop\",\n",
    "            \"home_indicator.x\", \"neutral_indicator\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_features = data_all[features]\n",
    "train_features = train[features]\n",
    "test_features = test[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = \"win_indicator\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_response = data_all[response]\n",
    "train_response = train[response]\n",
    "test_response = test[response]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_features_normalized = normalize(data_all_features)\n",
    "train_features_normalized = normalize(train_features)\n",
    "test_features_normalized = normalize(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get best neural net hyperparameters from HW1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network_results = pd.read_csv(directory_hw1 + \"ncaa_neural_net_grid_search.csv\")\n",
    "out_fold_cv_summary = neural_network_results.groupby([\"hidden_layer_size\", \"solver\", \"activation\", \"alpha\"])[\"out_fold_accuracy\"].agg([\"mean\"]).sort_values(by = [\"mean\"], ascending = False)\n",
    "optimal_results = out_fold_cv_summary.index[np.argmax(out_fold_cv_summary[\"mean\"])]\n",
    "hidden_layer_size_opt = optimal_results[0]\n",
    "solver_opt = optimal_results[1]\n",
    "activation_opt = optimal_results[2]\n",
    "alpha_opt = optimal_results[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the number of components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 1 | number of components: 1\n",
      "  iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0            1               750   adam       relu   0.05        0.517005   \n",
      "\n",
      "   test_accuracy      time  n_components  \n",
      "0       0.524488  3.042766           1.0   \n",
      "\n",
      "Iter: 2 | number of components: 2\n",
      "  iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0            1               750   adam       relu   0.05        0.517005   \n",
      "1            2               750   adam       relu   0.05        0.529620   \n",
      "\n",
      "   test_accuracy      time  n_components  \n",
      "0       0.524488  3.042766           1.0  \n",
      "1       0.532728  3.232441           2.0   \n",
      "\n",
      "Iter: 3 | number of components: 3\n",
      "  iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0            1               750   adam       relu   0.05        0.517005   \n",
      "1            2               750   adam       relu   0.05        0.529620   \n",
      "2            3               750   adam       relu   0.05        0.543480   \n",
      "\n",
      "   test_accuracy       time  n_components  \n",
      "0       0.524488   3.042766           1.0  \n",
      "1       0.532728   3.232441           2.0  \n",
      "2       0.539889  11.264042           3.0   \n",
      "\n",
      "Iter: 4 | number of components: 4\n",
      "  iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0            1               750   adam       relu   0.05        0.517005   \n",
      "1            2               750   adam       relu   0.05        0.529620   \n",
      "2            3               750   adam       relu   0.05        0.543480   \n",
      "3            4               750   adam       relu   0.05        0.554685   \n",
      "\n",
      "   test_accuracy       time  n_components  \n",
      "0       0.524488   3.042766           1.0  \n",
      "1       0.532728   3.232441           2.0  \n",
      "2       0.539889  11.264042           3.0  \n",
      "3       0.551363   4.000332           4.0   \n",
      "\n",
      "Iter: 5 | number of components: 5\n",
      "  iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0            1               750   adam       relu   0.05        0.517005   \n",
      "1            2               750   adam       relu   0.05        0.529620   \n",
      "2            3               750   adam       relu   0.05        0.543480   \n",
      "3            4               750   adam       relu   0.05        0.554685   \n",
      "4            5               750   adam       relu   0.05        0.561304   \n",
      "\n",
      "   test_accuracy       time  n_components  \n",
      "0       0.524488   3.042766           1.0  \n",
      "1       0.532728   3.232441           2.0  \n",
      "2       0.539889  11.264042           3.0  \n",
      "3       0.551363   4.000332           4.0  \n",
      "4       0.554520   5.817621           5.0   \n",
      "\n",
      "Iter: 6 | number of components: 6\n",
      "  iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0            1               750   adam       relu   0.05        0.517005   \n",
      "1            2               750   adam       relu   0.05        0.529620   \n",
      "2            3               750   adam       relu   0.05        0.543480   \n",
      "3            4               750   adam       relu   0.05        0.554685   \n",
      "4            5               750   adam       relu   0.05        0.561304   \n",
      "5            6               750   adam       relu   0.05        0.609305   \n",
      "\n",
      "   test_accuracy       time  n_components  \n",
      "0       0.524488   3.042766           1.0  \n",
      "1       0.532728   3.232441           2.0  \n",
      "2       0.539889  11.264042           3.0  \n",
      "3       0.551363   4.000332           4.0  \n",
      "4       0.554520   5.817621           5.0  \n",
      "5       0.602418   6.510945           6.0   \n",
      "\n",
      "Iter: 7 | number of components: 7\n",
      "  iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0            1               750   adam       relu   0.05        0.517005   \n",
      "1            2               750   adam       relu   0.05        0.529620   \n",
      "2            3               750   adam       relu   0.05        0.543480   \n",
      "3            4               750   adam       relu   0.05        0.554685   \n",
      "4            5               750   adam       relu   0.05        0.561304   \n",
      "5            6               750   adam       relu   0.05        0.609305   \n",
      "6            7               750   adam       relu   0.05        0.648067   \n",
      "\n",
      "   test_accuracy       time  n_components  \n",
      "0       0.524488   3.042766           1.0  \n",
      "1       0.532728   3.232441           2.0  \n",
      "2       0.539889  11.264042           3.0  \n",
      "3       0.551363   4.000332           4.0  \n",
      "4       0.554520   5.817621           5.0  \n",
      "5       0.602418   6.510945           6.0  \n",
      "6       0.643385  10.892198           7.0   \n",
      "\n",
      "Iter: 8 | number of components: 8\n",
      "  iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0            1               750   adam       relu   0.05        0.517005   \n",
      "1            2               750   adam       relu   0.05        0.529620   \n",
      "2            3               750   adam       relu   0.05        0.543480   \n",
      "3            4               750   adam       relu   0.05        0.554685   \n",
      "4            5               750   adam       relu   0.05        0.561304   \n",
      "5            6               750   adam       relu   0.05        0.609305   \n",
      "6            7               750   adam       relu   0.05        0.648067   \n",
      "7            8               750   adam       relu   0.05        0.647706   \n",
      "\n",
      "   test_accuracy       time  n_components  \n",
      "0       0.524488   3.042766           1.0  \n",
      "1       0.532728   3.232441           2.0  \n",
      "2       0.539889  11.264042           3.0  \n",
      "3       0.551363   4.000332           4.0  \n",
      "4       0.554520   5.817621           5.0  \n",
      "5       0.602418   6.510945           6.0  \n",
      "6       0.643385  10.892198           7.0  \n",
      "7       0.643693   6.507289           8.0   \n",
      "\n",
      "Iter: 9 | number of components: 9\n",
      "  iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0            1               750   adam       relu   0.05        0.517005   \n",
      "1            2               750   adam       relu   0.05        0.529620   \n",
      "2            3               750   adam       relu   0.05        0.543480   \n",
      "3            4               750   adam       relu   0.05        0.554685   \n",
      "4            5               750   adam       relu   0.05        0.561304   \n",
      "5            6               750   adam       relu   0.05        0.609305   \n",
      "6            7               750   adam       relu   0.05        0.648067   \n",
      "7            8               750   adam       relu   0.05        0.647706   \n",
      "8            9               750   adam       relu   0.05        0.649869   \n",
      "\n",
      "   test_accuracy       time  n_components  \n",
      "0       0.524488   3.042766           1.0  \n",
      "1       0.532728   3.232441           2.0  \n",
      "2       0.539889  11.264042           3.0  \n",
      "3       0.551363   4.000332           4.0  \n",
      "4       0.554520   5.817621           5.0  \n",
      "5       0.602418   6.510945           6.0  \n",
      "6       0.643385  10.892198           7.0  \n",
      "7       0.643693   6.507289           8.0  \n",
      "8       0.644848   8.521219           9.0   \n",
      "\n",
      "Iter: 10 | number of components: 10\n",
      "  iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0            1               750   adam       relu   0.05        0.517005   \n",
      "1            2               750   adam       relu   0.05        0.529620   \n",
      "2            3               750   adam       relu   0.05        0.543480   \n",
      "3            4               750   adam       relu   0.05        0.554685   \n",
      "4            5               750   adam       relu   0.05        0.561304   \n",
      "5            6               750   adam       relu   0.05        0.609305   \n",
      "6            7               750   adam       relu   0.05        0.648067   \n",
      "7            8               750   adam       relu   0.05        0.647706   \n",
      "8            9               750   adam       relu   0.05        0.649869   \n",
      "9           10               750   adam       relu   0.05        0.654653   \n",
      "\n",
      "   test_accuracy       time  n_components  \n",
      "0       0.524488   3.042766           1.0  \n",
      "1       0.532728   3.232441           2.0  \n",
      "2       0.539889  11.264042           3.0  \n",
      "3       0.551363   4.000332           4.0  \n",
      "4       0.554520   5.817621           5.0  \n",
      "5       0.602418   6.510945           6.0  \n",
      "6       0.643385  10.892198           7.0  \n",
      "7       0.643693   6.507289           8.0  \n",
      "8       0.644848   8.521219           9.0  \n",
      "9       0.644386  13.760489          10.0   \n",
      "\n",
      "Iter: 11 | number of components: 11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0   \n",
      "\n",
      "Iter: 12 | number of components: 12\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0   \n",
      "\n",
      "Iter: 13 | number of components: 13\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0   \n",
      "\n",
      "Iter: 14 | number of components: 14\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0   \n",
      "\n",
      "Iter: 15 | number of components: 15\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0   \n",
      "\n",
      "Iter: 16 | number of components: 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0   \n",
      "\n",
      "Iter: 17 | number of components: 17\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0   \n",
      "\n",
      "Iter: 18 | number of components: 18\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0   \n",
      "\n",
      "Iter: 19 | number of components: 19\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0   \n",
      "\n",
      "Iter: 20 | number of components: 20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0   \n",
      "\n",
      "Iter: 21 | number of components: 21\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0   \n",
      "\n",
      "Iter: 22 | number of components: 22\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0   \n",
      "\n",
      "Iter: 23 | number of components: 23\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0   \n",
      "\n",
      "Iter: 24 | number of components: 24\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0   \n",
      "\n",
      "Iter: 25 | number of components: 25\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0   \n",
      "\n",
      "Iter: 26 | number of components: 26\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0   \n",
      "\n",
      "Iter: 27 | number of components: 27\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0   \n",
      "\n",
      "Iter: 28 | number of components: 28\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0   \n",
      "\n",
      "Iter: 29 | number of components: 29\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0   \n",
      "\n",
      "Iter: 30 | number of components: 30\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0   \n",
      "\n",
      "Iter: 31 | number of components: 31\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0   \n",
      "\n",
      "Iter: 32 | number of components: 32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0   \n",
      "\n",
      "Iter: 33 | number of components: 33\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "32           33               750   adam       relu   0.05        0.700786   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0  \n",
      "32       0.693054  10.601487          33.0   \n",
      "\n",
      "Iter: 34 | number of components: 34\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "32           33               750   adam       relu   0.05        0.700786   \n",
      "33           34               750   adam       relu   0.05        0.700295   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0  \n",
      "32       0.693054  10.601487          33.0  \n",
      "33       0.692361  14.586159          34.0   \n",
      "\n",
      "Iter: 35 | number of components: 35\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "32           33               750   adam       relu   0.05        0.700786   \n",
      "33           34               750   adam       relu   0.05        0.700295   \n",
      "34           35               750   adam       relu   0.05        0.702097   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0  \n",
      "32       0.693054  10.601487          33.0  \n",
      "33       0.692361  14.586159          34.0  \n",
      "34       0.695595  15.560359          35.0   \n",
      "\n",
      "Iter: 36 | number of components: 36\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "32           33               750   adam       relu   0.05        0.700786   \n",
      "33           34               750   adam       relu   0.05        0.700295   \n",
      "34           35               750   adam       relu   0.05        0.702097   \n",
      "35           36               750   adam       relu   0.05        0.700950   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0  \n",
      "32       0.693054  10.601487          33.0  \n",
      "33       0.692361  14.586159          34.0  \n",
      "34       0.695595  15.560359          35.0  \n",
      "35       0.694825  11.291308          36.0   \n",
      "\n",
      "Iter: 37 | number of components: 37\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "32           33               750   adam       relu   0.05        0.700786   \n",
      "33           34               750   adam       relu   0.05        0.700295   \n",
      "34           35               750   adam       relu   0.05        0.702097   \n",
      "35           36               750   adam       relu   0.05        0.700950   \n",
      "36           37               750   adam       relu   0.05        0.697182   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0  \n",
      "32       0.693054  10.601487          33.0  \n",
      "33       0.692361  14.586159          34.0  \n",
      "34       0.695595  15.560359          35.0  \n",
      "35       0.694825  11.291308          36.0  \n",
      "36       0.688742   6.471251          37.0   \n",
      "\n",
      "Iter: 38 | number of components: 38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "32           33               750   adam       relu   0.05        0.700786   \n",
      "33           34               750   adam       relu   0.05        0.700295   \n",
      "34           35               750   adam       relu   0.05        0.702097   \n",
      "35           36               750   adam       relu   0.05        0.700950   \n",
      "36           37               750   adam       relu   0.05        0.697182   \n",
      "37           38               750   adam       relu   0.05        0.699934   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0  \n",
      "32       0.693054  10.601487          33.0  \n",
      "33       0.692361  14.586159          34.0  \n",
      "34       0.695595  15.560359          35.0  \n",
      "35       0.694825  11.291308          36.0  \n",
      "36       0.688742   6.471251          37.0  \n",
      "37       0.692977   9.113478          38.0   \n",
      "\n",
      "Iter: 39 | number of components: 39\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "32           33               750   adam       relu   0.05        0.700786   \n",
      "33           34               750   adam       relu   0.05        0.700295   \n",
      "34           35               750   adam       relu   0.05        0.702097   \n",
      "35           36               750   adam       relu   0.05        0.700950   \n",
      "36           37               750   adam       relu   0.05        0.697182   \n",
      "37           38               750   adam       relu   0.05        0.699934   \n",
      "38           39               750   adam       relu   0.05        0.699934   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0  \n",
      "32       0.693054  10.601487          33.0  \n",
      "33       0.692361  14.586159          34.0  \n",
      "34       0.695595  15.560359          35.0  \n",
      "35       0.694825  11.291308          36.0  \n",
      "36       0.688742   6.471251          37.0  \n",
      "37       0.692977   9.113478          38.0  \n",
      "38       0.692515   6.542508          39.0   \n",
      "\n",
      "Iter: 40 | number of components: 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "32           33               750   adam       relu   0.05        0.700786   \n",
      "33           34               750   adam       relu   0.05        0.700295   \n",
      "34           35               750   adam       relu   0.05        0.702097   \n",
      "35           36               750   adam       relu   0.05        0.700950   \n",
      "36           37               750   adam       relu   0.05        0.697182   \n",
      "37           38               750   adam       relu   0.05        0.699934   \n",
      "38           39               750   adam       relu   0.05        0.699934   \n",
      "39           40               750   adam       relu   0.05        0.698493   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0  \n",
      "32       0.693054  10.601487          33.0  \n",
      "33       0.692361  14.586159          34.0  \n",
      "34       0.695595  15.560359          35.0  \n",
      "35       0.694825  11.291308          36.0  \n",
      "36       0.688742   6.471251          37.0  \n",
      "37       0.692977   9.113478          38.0  \n",
      "38       0.692515   6.542508          39.0  \n",
      "39       0.692361  11.753432          40.0   \n",
      "\n",
      "Iter: 41 | number of components: 41\n",
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "32           33               750   adam       relu   0.05        0.700786   \n",
      "33           34               750   adam       relu   0.05        0.700295   \n",
      "34           35               750   adam       relu   0.05        0.702097   \n",
      "35           36               750   adam       relu   0.05        0.700950   \n",
      "36           37               750   adam       relu   0.05        0.697182   \n",
      "37           38               750   adam       relu   0.05        0.699934   \n",
      "38           39               750   adam       relu   0.05        0.699934   \n",
      "39           40               750   adam       relu   0.05        0.698493   \n",
      "40           41               750   adam       relu   0.05        0.699148   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0  \n",
      "32       0.693054  10.601487          33.0  \n",
      "33       0.692361  14.586159          34.0  \n",
      "34       0.695595  15.560359          35.0  \n",
      "35       0.694825  11.291308          36.0  \n",
      "36       0.688742   6.471251          37.0  \n",
      "37       0.692977   9.113478          38.0  \n",
      "38       0.692515   6.542508          39.0  \n",
      "39       0.692361  11.753432          40.0  \n",
      "40       0.692977   9.063922          41.0   \n",
      "\n",
      "Iter: 42 | number of components: 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   iter_counter hidden_layer_size solver activation  alpha  train_accuracy  \\\n",
      "0             1               750   adam       relu   0.05        0.517005   \n",
      "1             2               750   adam       relu   0.05        0.529620   \n",
      "2             3               750   adam       relu   0.05        0.543480   \n",
      "3             4               750   adam       relu   0.05        0.554685   \n",
      "4             5               750   adam       relu   0.05        0.561304   \n",
      "5             6               750   adam       relu   0.05        0.609305   \n",
      "6             7               750   adam       relu   0.05        0.648067   \n",
      "7             8               750   adam       relu   0.05        0.647706   \n",
      "8             9               750   adam       relu   0.05        0.649869   \n",
      "9            10               750   adam       relu   0.05        0.654653   \n",
      "10           11               750   adam       relu   0.05        0.655144   \n",
      "11           12               750   adam       relu   0.05        0.653801   \n",
      "12           13               750   adam       relu   0.05        0.686796   \n",
      "13           14               750   adam       relu   0.05        0.691022   \n",
      "14           15               750   adam       relu   0.05        0.692333   \n",
      "15           16               750   adam       relu   0.05        0.690990   \n",
      "16           17               750   adam       relu   0.05        0.690662   \n",
      "17           18               750   adam       relu   0.05        0.692005   \n",
      "18           19               750   adam       relu   0.05        0.695675   \n",
      "19           20               750   adam       relu   0.05        0.695347   \n",
      "20           21               750   adam       relu   0.05        0.697936   \n",
      "21           22               750   adam       relu   0.05        0.700131   \n",
      "22           23               750   adam       relu   0.05        0.698067   \n",
      "23           24               750   adam       relu   0.05        0.699836   \n",
      "24           25               750   adam       relu   0.05        0.697280   \n",
      "25           26               750   adam       relu   0.05        0.699279   \n",
      "26           27               750   adam       relu   0.05        0.699083   \n",
      "27           28               750   adam       relu   0.05        0.698034   \n",
      "28           29               750   adam       relu   0.05        0.701212   \n",
      "29           30               750   adam       relu   0.05        0.697903   \n",
      "30           31               750   adam       relu   0.05        0.700098   \n",
      "31           32               750   adam       relu   0.05        0.700262   \n",
      "32           33               750   adam       relu   0.05        0.700786   \n",
      "33           34               750   adam       relu   0.05        0.700295   \n",
      "34           35               750   adam       relu   0.05        0.702097   \n",
      "35           36               750   adam       relu   0.05        0.700950   \n",
      "36           37               750   adam       relu   0.05        0.697182   \n",
      "37           38               750   adam       relu   0.05        0.699934   \n",
      "38           39               750   adam       relu   0.05        0.699934   \n",
      "39           40               750   adam       relu   0.05        0.698493   \n",
      "40           41               750   adam       relu   0.05        0.699148   \n",
      "41           42               750   adam       relu   0.05        0.701933   \n",
      "\n",
      "    test_accuracy       time  n_components  \n",
      "0        0.524488   3.042766           1.0  \n",
      "1        0.532728   3.232441           2.0  \n",
      "2        0.539889  11.264042           3.0  \n",
      "3        0.551363   4.000332           4.0  \n",
      "4        0.554520   5.817621           5.0  \n",
      "5        0.602418   6.510945           6.0  \n",
      "6        0.643385  10.892198           7.0  \n",
      "7        0.643693   6.507289           8.0  \n",
      "8        0.644848   8.521219           9.0  \n",
      "9        0.644386  13.760489          10.0  \n",
      "10       0.645772  10.012314          11.0  \n",
      "11       0.644155   8.542188          12.0  \n",
      "12       0.682196  10.277148          13.0  \n",
      "13       0.684814   6.168742          14.0  \n",
      "14       0.686278   8.570710          15.0  \n",
      "15       0.687664   8.089501          16.0  \n",
      "16       0.685276   8.837928          17.0  \n",
      "17       0.688126   8.903936          18.0  \n",
      "18       0.689666  10.636717          19.0  \n",
      "19       0.690128   7.828372          20.0  \n",
      "20       0.691514  12.006714          21.0  \n",
      "21       0.693901  15.982802          22.0  \n",
      "22       0.689974   5.994241          23.0  \n",
      "23       0.692823   8.011618          24.0  \n",
      "24       0.690051   7.146838          25.0  \n",
      "25       0.694132   9.590281          26.0  \n",
      "26       0.689820   9.012695          27.0  \n",
      "27       0.694594   6.937427          28.0  \n",
      "28       0.694209  11.053204          29.0  \n",
      "29       0.691052   7.849469          30.0  \n",
      "30       0.692900   8.008624          31.0  \n",
      "31       0.692669  11.231892          32.0  \n",
      "32       0.693054  10.601487          33.0  \n",
      "33       0.692361  14.586159          34.0  \n",
      "34       0.695595  15.560359          35.0  \n",
      "35       0.694825  11.291308          36.0  \n",
      "36       0.688742   6.471251          37.0  \n",
      "37       0.692977   9.113478          38.0  \n",
      "38       0.692515   6.542508          39.0  \n",
      "39       0.692361  11.753432          40.0  \n",
      "40       0.692977   9.063922          41.0  \n",
      "41       0.695980  13.698432          42.0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Initialize an empty data frame for recording results\n",
    "neural_network_results = pd.DataFrame(columns = [\"iter_counter\",\n",
    "                                                 \"hidden_layer_size\",\n",
    "                                                 \"solver\",\n",
    "                                                 \"activation\",\n",
    "                                                 \"alpha\",\n",
    "                                                 \"train_accuracy\",\n",
    "                                                 \"test_accuracy\",\n",
    "                                                 \"time\"\n",
    "                                                 ])\n",
    "\n",
    "#Set hyperparameter space\n",
    "n_components = range(1, 43, 1)\n",
    "\n",
    "#Start an iteration counter\n",
    "iter_counter = 0\n",
    "\n",
    "#For each alpha, hidden layer size, and fold...\n",
    "#(using fixed solver and activiation function for now)\n",
    "for n_component in n_components:\n",
    "    \n",
    "    #Increment the counter\n",
    "    iter_counter = iter_counter + 1\n",
    "    \n",
    "    #Output message\n",
    "    print(\"Iter:\", iter_counter,\n",
    "            \"| number of components:\", n_component)\n",
    "\n",
    "    #Get the random projection\n",
    "    start_time = time.time()\n",
    "    \n",
    "    transformer = random_projection.GaussianRandomProjection(n_components = n_component,\n",
    "                                                             eps = 0.1,\n",
    "                                                             random_state = 28)\n",
    "    train_features_normalized_randpro = transformer.fit_transform(train_features_normalized)\n",
    "    test_features_normalized_randpro = transformer.fit_transform(test_features_normalized)\n",
    "\n",
    "    #Get the neural net object\n",
    "    neural_network = MLPClassifier(solver = solver_opt, #lbfgs, adam, sgd\n",
    "                                   activation = activation_opt, #identity, logistic, tanh, relu\n",
    "                                   alpha = alpha_opt,\n",
    "                                   hidden_layer_sizes = (hidden_layer_size_opt,),\n",
    "                                   batch_size = \"auto\",\n",
    "                                   learning_rate = \"constant\",\n",
    "                                   learning_rate_init = 0.001,\n",
    "                                   power_t = 0.5,\n",
    "                                   max_iter = 200,\n",
    "                                   shuffle = True,\n",
    "                                   random_state = 28,\n",
    "                                   tol = 0.0001,\n",
    "                                   verbose = False,\n",
    "                                   warm_start = False,\n",
    "                                   momentum = 0.9,\n",
    "                                   nesterovs_momentum = True,\n",
    "                                   early_stopping = True,\n",
    "                                   validation_fraction = 0.1,\n",
    "                                   beta_1 = 0.9,\n",
    "                                   beta_2 = 0.999,\n",
    "                                   epsilon = 1e-08,\n",
    "                                   n_iter_no_change = 10,\n",
    "                                   max_fun = 15000)\n",
    "    \n",
    "    #Fit the model\n",
    "    neural_network.fit(train_features_normalized_randpro, train_response) \n",
    "    \n",
    "    #Evaluate the model\n",
    "    #In fold\n",
    "    train_accuracy = neural_network.score(train_features_normalized_randpro, train_response)\n",
    "    #Out of fold\n",
    "    test_accuracy = neural_network.score(test_features_normalized_randpro, test_response)\n",
    "\n",
    "    end_time = time.time()\n",
    "    total_time = end_time - start_time\n",
    "\n",
    "    #Add to results list\n",
    "    neural_network_results = neural_network_results.append({\"iter_counter\": iter_counter,\n",
    "                                                            \"n_components\": n_component,\n",
    "                                                            \"hidden_layer_size\": hidden_layer_size_opt,\n",
    "                                                            \"solver\": solver_opt,\n",
    "                                                            \"activation\": activation_opt,\n",
    "                                                            \"alpha\": alpha_opt,\n",
    "                                                            \"train_accuracy\": train_accuracy,\n",
    "                                                            \"test_accuracy\": test_accuracy,\n",
    "                                                            \"time\": total_time},\n",
    "                                                            ignore_index = True)\n",
    "    print(neural_network_results, \"\\n\")\n",
    "    neural_network_results.to_csv(directory_hw3 + \"ncaa_rp_neural_net_optimization.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
